### [[3.5: Evaluating changes.]]

Now that we have established how to set up Attribute Axes, Priorities and create Axioms we can start to look at how to make evaluate changes, before making them and afterwards.

Let's start by creating an example problem, by setting up the environment for it, current state, and our goals (end state).

Let's start with a simple website with some dynamic content, which we are deploying.

Our goal is to improve our performance in doing the deployment.  Currently, we are copying the installation files sequentially from a single server, and we have 100 web or application servers which we are copying them to (we will call them "web" servers for simplicity).

The exact mechanisms for copying and deployment are not going to be the focus of this example, and so we won't be evaluating their performance or impacts, because it will complicate the example.  In the real world, of course, these factors are also important, and would have be evaluated independently, and in conjuncture with the rest of the changes.  

It is important that all details are "Aligned" in that they work well together, and perform efficient as a whole (in their sequential and parallel processing), over long periods of time, and under our given resiliency goals.  Alignment is complicated to explain, so I will keep giving examples of it over time, so that you can build up your own understanding of the concept, and how to apply the term as I am using it.

So, we have a current state:

- Single server, connects to 100 servers over SCP (secure copy) sequentially.

What are some options that will perform better than running 100 sequential copies?

One method is running the copies on the same single server, but running the copy commands in parallel instead of sequentially.

There are a number of options for running things in parallel:

- Forking the process, so that there are many processes of SCP running.  Forked processes are independent of the process that forked them (they start as clones, and then do their custom thing), and do not have a lot of communication with the parent.  There are ways to know some things about the program though, so this is a viable option.

- Using a controller program to create Threads, and running the SCP process in the threads (similar to forking, in that there are still 100 (in this case) SCP processes being run, but they are being controlled by a single program, instead of just independently launching.

Since I want to constrain this example, I won't get into the differences between controlling forked and threaded sub-processes, it's enough to know that while they have differences, we can get the results we want out of either of them for this case.

{{ todo__describe_forked_vs_threaded_somewhere_else }}

It doesn't matter whether we write our own code to do this forked or thread handling, or we use software someone else made, such as "Orchestration" software which might have agents that run on each target server, and perform the copy in it's own way.

So we have specified 2 methods running on the same single source server, and performing the work in parallel.

Since we have run into this performance problem by running things sequentially, one thing we will do is say, "Let's not get into this situation again, once our server targets have grown again", and say that we are removing the option of using sequential copies again, because it will not scale, and will create work for us again in the future.

Since we just went over how create an Axiom, let's do it now.  However, since we are working with a specific scenario and have not yet looked at all-of-operations together, we shouldn't make this a Universal Axiom, or a Production Axiom.

Instead, let's make it a Working Axiom, or a Temporary Axiom, for the purpose of this problem.

Here goes:

"Once a job that was working sequentially on a single server hits a scaling problem, and needs to be changed for performance, all later implementations of that job will not be re-implemented sequentially, even on more than a single server."

This is a little longer than I like for an Axiom, and it has more caveats than I prefer as well, as I like them simple and straight-forward, always able to be applied.

In this circumstance, we are building a Working Axiom, so it is temporary, and it needs to be precise, so it needs those caveats to fit into our problem space.

Let's review the verbiage quickly to see what caveats I baked in:

- I have limited this to implementations that already exist, and were implemented as sequential processing, on a single instance.

This could actually apply to a number of different scenarios, not just the one we are currently discussing, so this is good Axiom material, as we want to be able to apply Axioms generally, so that they are usable or actionable.

- I specify that this axiom is only to be applied once the work hits a problem.  Going around and "fixing" problems that aren't problems is a poor use of resources, as there are likely actual problems that need fixing.  Also, it is creating change in the environment, which may lead to instability or outages.  

All changes come with risk, as you only know the effects of your previous system from your history with it, once you change it you are working with a new system (new state vs. old state), so you may get different effects.  

If your change is implemented ideally, then the effects that change are exactly what you planned and wanted, so everything is OK.  If you get effects you did not want, or did not anticipate, you will likely be created a problem, which may need another change to fix.  In cases where it causes an immediate outage or degradation, it will need to be reverted or "rolled-back", if this is possible.

- Once a job gets to this "problem" state, we will not create another solution that operates sequentially, as we have proven that for this case of work (job), sequential processing doesn't scale for us.

This doesn't meant that everything should be parallelized.  Firstly, not everything can be run in parallel, as some operations are sequential operations.  If you need to get data, and then format text with it, you can't format the text at the same time you are getting data (in parallel), because you don't have the data yet.  This work requires being run sequentially.  However, if you have to process 100 of these, you may be able to run each of the 100 jobs in parallel, and then internally process them sequentially.

Writing things to work initially in sequence is a faster way to to develop, as the complexity of parallel process communication, locking and other issues can be ignored, and sequential processing is a default for many implementation languages (and all the primary Operational related languages, from any environment I've worked in).

- Finally, I state that even splitting the job across multiple servers, which may allow the sequential processing to have acceptable performance again, is not acceptable, because we are just planning to have this problem again when those N servers have to do "100" servers each, and we are back in the same spot.  This method of "throwing hardware at the problem" is frequently not the right move, although there are some special cases where it is the right move, which we will get into later.

The act of taking the same method you use now, and making a change to it that allows it to continue working, but with the knowledge that it will stop working again once you have continued growing as you have previously, I sometimes call "burying land mines in your own yard".  This is because you know this will create a problem for you in the future (problems, degradation, outages, etc), but you are doing it anyway.  You have embedded a known problem in your system, and will certainly encounter it again (unless you are going to decline and shut down the organization).

However, just because this is going to create a problem in the future, and is would be best to be avoided, there are circumstances this might be the "right thing to do".  Such as if you are working in a "Startup" organization (very small, moving very fast, not afraid to break things), and the trade offs are worth it.  

Doing things or not doing things should always be evaluated for their Engineering trade-offs, with the business goals and requirements.  Refusing to do something that is best for the organization, just because it will cause a problem in the future is also Not Engineering, even though it seems like it is "being a better Engineer", because it is not taking into account the actual environment, which is prioritizing moving fast over avoiding problems.  This will create Technical Debt, but may be worth the trade-off, just like creating Financial Debt can.

Ok, so now we have established that one method of solving this problem is to create parallel processing on the single server, and we have our Working Axiom:

"Once a job that was working sequentially on a single server hits a scaling problem, and needs to be changed for performance, all later implementations of that job will not be re-implemented sequentially, even on more than a single server."

We need at least one more method for this example to be complete, for our purposes (but not for a real world solution), and for that I will choose the method of the target servers all pulling down the deployment themselves.

This creates a "push" (parallel SCP copies) vs. "pull" (target servers pull down data) scenario, so we are comparing data moving in two different direction.

For this example, I will only provide 1 method of "pulling" the deployment data, which will be to use a Load Balancer and web servers behind the Load Balancer.

For all Production services, we should generally always have at least 2 servers for redundancy, in case one of them fails the other is available.  Note I say "generally always", which is a contradiction, but we will have to talk about this later.  However, for this example, to keep things simple we will just create a single Load Balancer and N web servers behind the Load Balancer.  For the example, we could say 1 web server, but since the purpose of Load Balancers is to distribute requests (load), we can say N.  Getting into 2 or more Load Balancers has a couple other issues I would want to bring up, so I will avoid it for this example.

So, to summarize, our "pull" alternative is:

- A Load Balancer server that accepts HTTP requests (also simplifying by not adding in security, made clear by not using HTTPS).

- N Web servers that can server the static content of our deployment data.

- Some Logic for invoking the "pull request" from the target servers, to the Load Balancer.  We will call this "Pull Logic".

- Some Logic for signaling the target servers that they should invoke the "Pull Logic".  We will this "Deploy Logic", since this invokes the deployment.


The flow of this Pull system will be:

- The new deployment data is put in place, in whatever way that is done, which is the same for any of our cases.

- Deploy Logic is triggered, by a Human running a script or initiating from a webpage, etc.

- The Deploy Logic triggers the Pull Logic to get the latest data.  This could also be done several ways, but let's take the simplest one of an Agent Model, where the Deploy tells each of the web servers it's time to Pull their deployment data.

- The Pull Logic makes an HTTP request to the Load Balancer, which proxies the request to the HTTP server, which responds with the Deployment Data.

- The standard "local installation" Logic runs on the web server node, which would run in any of our cases.


So, now we have established a more scalable Push and a Pull alternative to our sequential Push mechanism, how should we go about evaluating them?

First, let's come up with all the Attribute Axes that we care about here, and then let's prioritize them for ranking purposes, and finally we can assign values to all of the Attribute Axes, and then look at what their Prioritization tells us about what our options are.

One important concept to always be aware of when designing a solution is Centralization.  Let's create that spectrum:

Decentralized (0.0) <---> Centralized (1.0)

On the Decentralized end of the spectrum, things are done on many nodes (machines, servers, etc), and on the Centralized end of the spectrum, things are done in a single place.

The benefits of Centralization are control, and a single point to detect failures and perform control logic.

The liabilities of Centralization, or the benefits of Decentralization, are that there are many nodes, so if a node fails, you only lost 1/N of the total processing capacity, this also can help with performance as many nodes can do more work than a single node.

However, we actually have 2 sides to this Centralization question.

Firstly, we are always Decentralized on our HTTP servers, because we have more than 1 of them, or N of them.  So our Target is already Decentralized.

The question is whether we will make our Source Decentralized (HTTP servers behind load balancers), or our Source Centralized.

There is a slightly different perspective on this already going on with Sequential vs. Parallel execution on a single node.  Parallel execution has a "Decentralized" factor over a sequential execution, which is the Centralization of an execution process.  The differences between running many processes on the same server or running many processes on different servers have many similarities.

Now that we have this Centralization spectrum, let's put our options on the table:

- Push: Centralized execution of parallel processes.  While there is an element of Decentralization to the Parallel processing vs. sequential, this operates under the black-box of this server, since it is on a single server, it is still a 1-instance system, and so is fully Centralized.  Centralized = 1.0.

- Pull: We initiate it on a single machine, that contacts 100 machines, those contact 1 machine (Load Balancer), which contacts N machines that serve static HTTP.  This has a back-and-forth in terms of being Centralized as we move from 1-instance to N-instance, back to few-instances (1 Load Balancer), to N-instances (HTTP) again.  However, when we black-box this, the important part is that the 100 machines (N-instances) are requesting their deployment data independently:  this is Decentralized intallation, so Centralization is closer to 0.0, but probably not full 0.0, since there are many centralized steps, let's call it Centralized = 0.2.

Even in creating a simple set of values for comparison on a single Attribute Axes, we found there are many sub-points that could confuse the topic, and be causes for disagreement.  I'm able to settle these quickly in this text, because I don't have to have anyone else agree with my assessments, but as soon as you add in other people you quickly get disagreements based on terminology, experience and understanding of the current problem and previous solutions.

This makes this kind of thing essentially an unsolvable problem in terms of communication, and underlines how important it is to try to communicate clearly, like with Prioritized Attribute Axes, as it allows for some resemblance of qualified and quantified discussion, instead of the usual method of making decisions in groups:  who can talk the most, who can talk the loudest, who is better at arguing and the most important, who has the most social capital to spend on "winning" the current discussion.

Since we are looking for Engineering clarity as opposed to "winning" through rhetoric, we must make our best efforts to perform this work clearly, even though as we get into the details of any topic it obviously becomes unclear and could be subjectively argued to mean the opposite thing.  Your experience and discretion will determine what path you go down, so paying attention to the results (effects) of all your actions will need to be your guide in how to make these choices to get effects you desire, and avoid effects you do not.

So we have a Centralized axis, and Push = 1.0, and Pull = 0.2.  We have one Attribute Axis filled out.

What's another spectrum we can measure here?  Performance is important, since that is why we are doing this exercise.  So let's rate them both:

- Push: N parallel SCP processes start, and copy the tarball or otherwise single-file packaged deployment data to each node.  Starting 100 SCP processes at once can delay things moving as the handshakes are occurring, but once things start up being in a single SCP process versus an HTTP process will only have the encryption as an added factor, which is fairly minimal on modern hardware and can be ignored unless it can be measured to be important.

- Pull: 1 process initiates 100 processes, which make an HTTP request through a load balancer to our HTTP servers.  We never did cover how the 1 process will initiate the 100 processes; if we use SSH to do it, we are literally doing the same thing that the 100 SCP processes of Push would do (since SCP uses SSH), except for the data delivery.

All in all, I'm going to round these out to being equivalent, which means between them we can put both their Performance scales at 1.0, which means it is a non-factor.

What about Scalability?  This is another factor like Performance.  We came to this problem because the Sequential Push was too slow.  It was not too slow when we had less than 100 servers, but at 100 servers it is too slow, which makes this a Scalability issue.  So let's rate our methods in terms of Scalability, after we make a spectrum:

Can't Scale (0.0)  <--->  Can Scale (1.0)

Notice I said "Can't Scale vs Can Scale", and not "Not Scalable vs Scalable".  The reason for this is that we may still need to change our selected solution, as it is not the "Most Scalable" solution, but building the "Most Scalable" solution before you need it is not good Engineering, as it is overkill for what we need.  We only need to handle our current and near-future problems, not our far-future problems.  Implementing a solution for far-future problems may actually cause us problems in building, supporting and using it now that we are not nearly at that scale.

Imagine a deployment system that can handle quickly doing deployments on 100,000 servers.  Is this going to be as easy to use, create and maintain as one that can deploy on 300 servers?  Probably not, as the mechanisms that will allow it to scale to 100,000 servers probably add in a lot of complexity and will make it difficult to use this system, and to make changes as the business goals change.

So let's review our Push/Pull options on the "Can't Scale" vs "Can Scale" spectrum:

- Push: Runs on a single machine with 100 processes.  This only scales up to what this single machine can handle, so at some point we are going to need to move to more than 1 initiating server.  So this is only scalable for so long, and then we will need more machines to perform this copy, and we will need a method to initiate all those machines to initiate their copies.

- Pull: Has 2 limited server groups (initiating, load balancing) and 2 scalable server groups (target servers, HTTP static content servers).  This has a much better scaling factor, in that our "limited server" groups are actually easy to expand.  It is easy to add more Load Balancers, and easy to split up Initiators, as they do a small workload (triggering the deployment fetching Logic on the target nodes).  Additionally, since the initiating Logic (Pull) does less work than the copying Logic (Push), we can run more target node initiations from a single Pull-instance server.

So, with this I'm going to assign some values based on my internal experience and understanding of this space.  It would take too much space to go into all the decision points I am making to assign these values.  As an exercise, do your own analysis on this and come up with your own values, and compare them to mine.  Why do you think we came up with different values?  This will happen with every person you work with, if you both have different ideas for how to implement things, so it is a useful exercise.

