### [[2.5.5.3.2.2.1: Changes to data, that meets constraints, will not harm other data, but can harm Logic that acts on the data (results of Logic, rather)]]

When working with Data, is it required that certain constraints are met.  This is normal database 101 stuff.  If you have a relationship between 2 tables, the the primary key of Table A is referenced in Table B, and then you change that primary key in Table A, but do not update all external references to it (such as in Table B), then you will have created an inconsistency.

There are methods for forcing this to not be allowed in many database software's schema configuration, using constraints and foreign keys, etc.

In an Operational Automation environment it is likely that the data sets will stay small enough that you can work with these constraints enabled, and the changes are important enough to deal with the performance hit the constraints provide anyway.  So, I recommend leaving them on, and letting the database software manage enforcement of constraints.

If you find yourself in a place where constraints are causing a real performance problem, and are not working, I suggest only turning off the constraints that are the problem points, and leaving the rest of them enabled.

For the areas where data constraints are turned off, you must be especially careful when making changes to this data not to lose any of the referential integrity that the constraints would have provided, with your own changes via Logic, or in unfortunate times when you manually update the database (which you should try to never, ever do).

Another Knowable thing about Data, is that if you have these constraints active, then you can Know that the data is correctly configured, and it's referential integrity is consistent.

There are some operations, such as dumping data and mass-importing it, that can cause these checks to be turned off, so be careful when you do this to do everything that is involved at the same time (all tables that reference each other), to ensure that you have not imported things into an inconsistent state.

We've now covered that Data can have an additional area of Knowability.  How does this relate to Logic?

Well, it turns out this is another area where Logic provides a fundamental weakness, and in a way that is Unknowable.

You can have perfectly consistent and correct Data, with all constraints active, and have Logic that works perfectly well with all of the current data.

And then you can make a change to that Data, which does not violate any of the comprehensive validation tests, and yet afterwards the Logic fails against the Data.  How?

Logic is not actually tied to Data in that same way that Data can be tied to itself.  In a database, let's use an abstract general SQL database with transactions for this case, we can insert a row into database table, that is perfectly valid, and all the tests are made in the transactional commit process, and the data is put through correctly.

When the Logic next tries to access this data, it finds the new table row, and it goes about it's normal logic, which has always worked before, but this time the data it receives is not something the Logic accounted for.

Say you have a field that is an unsigned int(11), so it goes from 0 to 
