__Operational Engineering and Automation__

- Terms:  Use these as Proper Nouns, so they obviously mean one-and-only-one thing.
  - Logic: code
  - Data: data
  - Rules: policies about how you do stuff
  - Distributed: dealing with N nodes
  - Real/Virtual.  Strict definitions.
    - Physical
      - Matter, Eletricity
    - Virtual:
      - Data, Logic

- Deal with ONLY effecs.  No side effects.
  - Show positives, not negatives.
    - How to produce low-downtime.  How to produce high-downtime.  Functinally positive or negative on our Axiom spectrums.  As prioritized by the 90-9-.9-.09... rules.

- Be clear about the differences:  Physical (Real), Logical (Virtual), Data (Virtual)
  - Can never know everything about something Real (physical), because of limited insight into what is going on with it
  - Can know everything about Virtual (Logic/Data), because they are limited, and they are fully contained and inspectable.
    - However, between Data and Logic is a huge gap, as Data is "perfectly" understandable, while Logic is not, due to Halting Problems and all other things CS-academia knows and describes very well.
    - This difference also tells us why Data is more important than Logic, because Data is more trustworthy than Logic.  When making changes to data, the changes are straight-forward to understand, when making changes to Logic, the side-effects (unintended consequences) can be far-reaching and completely not understandable, and frequently enough are this way.
      - Changes to data, that meets constraints, will not harm other data, but can harm Logic that acts on the data (results of Logic, rather)

- Introduce Intelligence.  Actionable Intelligence.

XX- This is written an as Apprecenticeship book.  I dont know you, but I am going to act in the role of a Master-Apprentice relationship, as I feel is most beneficial to an Operational Engineering role.
  X- Save this stuff for the "General Advice" section
  
  - Network Operations, Datacenter Operations, Server Operations are complex real-life fields, that are very Industry and less Academic.  Though all things can be studied in Academia, it does not make the results of those studies easily applicable to their real-world counterparts.  Since I have spent my time in Industry and not Academia, this is my approach and I will pass this apporach on to you.

  - Hopefully you, the reader, finds this useful and not distracting, but if it does feel wrong or distracting to you, I hope you can see it for the teaching device that it is, and can still take the information I am trying to impart regardless of not preferring the method I am using to deliver this information.
  
  - State I will get some things as PERSONAL PREFERENCE, and explain why, and these should not be confused with non-personal preference sections, where I am stating how to work analytically and logically in this domain.
    - **** I should have a DISCLAIMER in every single place that I make a personal preference known, like in the little side boxes or whatever.  ****

- What:  Describe both general automation and building an "OpsDB", separately.  So go over just the automation stuff, then how that relates to building an "OpsDB".  That gives this book a general purpose, and specific purpose.  This means it has informational and call-to-action together, so the OpsDB is the "example" for the informational, and the information supports and explains the OpsDB principles.


- Focus on the virtual/physical management, specifically around internet and network services, but relatable to other industries.  All use cases will be around data centers and networked services.

Your OpsDB is the desires and actionable knowledge of your company.  Everything inside it can be acted upon, it is better global information than any single person can have, so it is the best communication mechanism for a system that has multiple people with their own information (all companies over 1 employee).  Synchronizes information, makes transactional.

Setting realistic expectations for this project will be one of your biggest challenges.  Once the premise is understood, it is difficult to stop "magical" thinking about the project, as the intention is to solve all solvable problems, people see it as a magic machine.

It is a system or "machine" that can be used to solve all problems, in that it is a centralized database and method for acting against that data.  That is immediately a universal set of tools, because every piece of software is data with a method for acting against it.

The difference in this type of system

- An Explanation of what Operations.  And why every company is an Operations company (internet or not), and how now almost every company is first and foremost an Ops company, though almost no companies recognize this.
  - Their ability to stay online and available and provide their service is what keeps them making money.  How is this not a core-service?
    - Just because its Core doesnt mean they need to own all of it, but as they grow they will pay more and more for what they do not control, and control well.
      - Typically companies still dont tell ops departments that they need anything, until its due, all decisions are done, and its time to roll out.
        - The ops department is blamed for all lag.  Developers are blocked, legitimately and not-legitimately.
          - Everyone doing everything themselves is great for a boot-strap project, but just does not work in a Mission-Critical environment.  Launch NASA rocket with newbies running things?  No, experience is needed for precision and taking into account All The Things.
          - Balance to this.  What can be self-service, and what cant.  PaaS for production, IaaS for development and Ops usage.

- Ops is about Control.  Letting everyone do their own thing is not-control.  You can move faster, but not in an aligned way.
  - Alignment takes "vision" and knowledge.  Not someting someone new to the process can understand well, because they are new.
  
- Explain the skill ladders.  Infinitely many ladder, infinity tall ladders.  In each area you need to advance and learn, and as you do more ladders are climbed
  - Show it like a Graph:  mwMmwnUvMMm, ups and downs in different areas.  How to test yourself, understanding your skills.  Completition of projects as proof of skill, etc.
  - Know that no one else can know your ladder positions, though they can attempt to estimate, and people are always trying to determine pecking order between themselves and other people, and often to change the pecking order by politics and power.

- The OSI layer for getting things done:
  - Physical.  Real world things.
    - People are always required for real world things, because robots arent good enough yet.  Physical must manage physical.
  - Configuration.  How real world things are configured.
    - Logical.
  - State.  How real world things are managed.
    - Logical.
  - Automation.  How software can manage configuration and state.
    - Automation ends where people begin.  If you have no automation, the people manage the config and state.
    - Automation is the control of logical devices and state.  It does not control Physical devices, but does control their state.  (Even in the case of directing a physical robot, the automation updates state, and it takes something physical (motors, servos, cogs) to make the physical thing move.)
  - Process (and Procedures).  How people work around the lower levels.
  - Policy.  Dictates how processes can be implemented.  Policies may be directly contradicting Process, such as "No one is allowed to X", while a process requires a person to do exactly that.
  - Business...  Business goals
  - Political.  The realities of the business goals, determined by how well people will work together to achieve them.
  - Financial...  Financial reality, approved or not.  Timing.  Delays.
  - Legal...  Hard stop, must change direction if told by legal.


- How things break.  Velocity of Activity, Rate of Change, Volume of Change, Individual units (people or processes) involved in the changes.
  - Comparison (sprectrum) of adding more worker units (people or automation) to a process increase complexity, and thus make more risks.
  - Different data sources ensure automation is not possible.  "Automatability spectrum" problem.

- How to troubleshoot problems.

- How to construct an unbreakable process.  How to stop that process from being completed/sealed, so that it breaks.  How to ensure it breaks all the time, by setting conditions accordingly.
  - Faux-automation.  Manual automation.  Automation-assist.  Full-automation.  Comprehensive Life-Cycle automation.

- Philosophy: 
  - Axiomatic Engineering.  My method for making decisions that are not personal, even though of course they are my personal understand and information matching to the algorithm.  Present a method for discussing engineering in this manner..
      - 90-9-.9-.09% rules for priorities.  Make up your own rules if this doesnt work for you.  How to present them to people, a plan on improvining presentation.  A plan on requested for improving presentation.    If you dont come to common terms, you arent really communicating, talking past each other.
    - Fashion Based Engineering.  "Blogineering".  real evaluations of the environment, agreement between team on details, moving forward.  How to do it quickly.   Honesty in public relations, be skeptical of the claims of others.  No one will state they are fuckups, but that doesnt mean they arent asked to blog about their operational endeavours anyway.  What works for them may not work for you, apply Axiomatic Engineering principles, decided by you and your team.  Use everyone for source information, but nothing as universally applicable.  It's just another idea, including this one.  In-take, evaluate, match to your environment (synthesize), iterate, evaluate, repeat.

  - When to use statistics.  When they are applicable, when they are not.
    - Across many things: appliable
    - For a given thing: not applicable.
    - Give mental exercises to prove this.


    ** Have "Wouldnt it be nice?" sections, where I posit what would be improvements I have yet to experience.  Coming to terms, agreeing on the foundational details, agreeing on the axioms, agreeing on how to relate data to the axioms.  Agreeing on how to act against axioms.  With these done, we can work much better as a team, and discuss them.

   - Perfect is the enemy of done.  Worse is better.  How many safety can you afford?
      - Quality is never #1, utility is.  Once it's "good enough", it is abandoned for higher priority things.

  - Understanding Engineering:  Environment -> Resources -> Goal -> Actions -> Changed Environment -> Desired Effects?  Efficient use of resources?  Management of environment?
    - The use of resources (overall time, people time, money, hardware, etc) to create desired effects, for a given environment.
      - Evaluate the environment.  Know the present.  Real vs. virtual/logical.  
      - Modeling.  Creating models to understand.  Creating models to control.  Not the same.
        - Black boxing the world.  Pragmatism and effect driven models.  Input, Output, Side-Effects.
      - Algorithms: Idempotency, Sequence, 
      - Centralized vs. Decentralized.  Push vs Pull, when is it centralized?  Do you want tight control, or loose control?  Both have their effects.  People typically want tight control, or the effects of tight control (knowledge that it worked).
      - Distribute Systems.  Many node problems.
      - Distributed Data.  Where is the good data?  Where is the active data?  Are they the same?
      - Utility vs. Cloud vs. Old-School:  On Demand vs. Full Anonymous vs One-Off.
        - Named servers (1-1), position and datacenter are known.  Utilty is anonymous server, not anonymous location, position unknown, location known.  Cloud is anonymous name and location.  You dont care what server in a DC it is, or what DC it is in.
          - What do you have to care about?  The exact machine?  The DC in general?  Nothing, only that the service is reachable, and it can be reachable from anywhere?

  - Introduce spectrum of automatability.  How automateable is something in configure X vs Y?  This is automatability.
   - Working with N axis data for evaluation of properties.  Properties are scalar, but there are many dimensions to measure, and collectively they are near-infinite.
     - Tuning your goals based on your methods.
     - How to create your own Axioms.  Some standard axioms.  Axiomatic development.
     - Tools to fit the job.  Testing in an operational environment.  Mock-tests, etc in a world of only side effects.  Using Vagrant and VMs to test allows these side-effects to be tested, but take time to set up.  Worth it, but you may not start there in a live environment because of all the legacy that would have to be replicated and is changing all the time in non-standard ways.
    - How to standardize things.  Simplification.  The benefits and limitations.  Simpler means less options at any given time.  1-1 work is infinite precision and difficult to scale.  Simpler is can be deep precision in 1 or several ways, but does not allow all options.  Build your option matrix out of what you need, ensure all your use cases are covered.


  - The Data (base)
    - Modeling off of reality.  Logical ideas change all the time, business decisions and directions change all the time, staff changes regularly, reality will hold true, but it's perceived differently by everyone.  Still trying to map to reality gives the most common information to the most people who will work with it, and a common method of communication, and is therefore better than not.

   - Naming conventions.  Set them and try to abide by them consistently.  This will determine how frequently things must be looked up to be used, for someone familiar with the sytem.  Python vs PHP.
   - My rules:  No plurals in data (code is ok), strict lookup methods, limit methods of relationality.  DAG lookups, with normalized relations in data (not-DAG, has cycles, data doesnt have a direction when there are cycles, the search could start anywhere).

   - What tools you will need to manage this data.   Problems with ORM, problems with non-ORMs.  The tools chosen will determine the level of automatability.

 - Data survives longer than code/logic, business logic stays all the time, but the assets described in the DB remain the same, even if they are used differently, and different meta-data is stored about them.

- Building the logic system.
  - Ensuring uniqueness of elements that require guarantees.
  - Infrastructure.  Pre-Services.
  - Configuration of Services.
  - Monitoring of Services.
  - Life-Cycle Management of services.

- The process of building this system in your organization.
  - Collect all unique data in one place.  Ensure it is accurate by checking against reality, and combing through it manually to see if things line up, spot checking and automation checking every one by script.
  - Things that are unique to you, vs things that are general to everyone.
    - FQDNs, IPs, HW specs, OS specs, configuration variables, specific workflow and stuff.

- Imaging vs re-building from scratch
   - Correctness, up-to-date, vs speed.

- The layers of an automation system:
  - Description of environment
  - Provisioning
    - One-Time configuration
    - Continuous Configuration
    - State management
    - One-time actions (manual state control of distributed systems)
    - Maintenance actions (taking offline)
    - Marking broken HW, fixing HW, migrating OS positions.
    - What stays the same, what changes?  IPs for LOM on HW.  IPs for OSes on virtual.
    - Tracking N things.  Primaries vs. position.  Ordered lists are the best?

- Flexibility and dangers of an automation system.

- How to "translate" data changes, making many changes at once, like matrix multiplication.  Changing from Puppet to Salt, etc.

- The difference between App software dev, and Operational dev.  Robust, resilient, correct, handles failures, assumes failures will occur, is designed around failures occuring, instead of App designed around all functions being available (for the most part).

  - This can be represented in a spectrum.  Ops  <---->  Application.    Backend  <--->  Front End
    - HTML pages are very front end, web servers are less front end, DBs are less front end more back end, and OpsDB is most backend.


- Troubleshooting.  Cencentric circles.  Locality.  Intermittent vs. sustained.  The attributes of failures.
  - Determines monitoring.

- All processes can be automated to get a desired effect, if enough information about it is known.

- Evaluating changes.

- Automating anything

- Data Driven Design:  My methodology.  Start with the data, work from there.  Testing against data is key.  
  - Separate data changing logic from non-data changing logic.  This is like the Model/Controller separation, but is different because it is about any type of action, not just GUI-like actions.
  - Work systems.  Distributed Job schedulers.  
  - Collection of data:  Events (logs/etc), Time Series, Config State (md5sum, etc), Active/Live State (up/down)


- Systemic Thinking.  Philosophers Knife.  Slicing the pie vs Aggregation.  Completeness, ease of understanding, ease of building, life-cycle maintenance.  Where do you spend your time?

- Total elimination of manual work.  How to remove classes of work from being necessary.

- Building the data and action chains, to create all workflow.

- The data requirements:  Authentication, Authorization, Versioning, Change Management, Deployment, Pre-Post Deployment Actions, Schema Management

- Code management.  How to canary.  How to test.  Vagrant and virtual testing.


- Data Driven Development.  My methodology.
  - Start with data.  Fo over all features as represented in data.  

- Distributed OS.  DOS.  N units, all being controlled, configured and scheduling work.
  - Does not need a "traditional" cluster scheduler.  Can use these these for "cron" type jobs though.


- How to select:  Frameworks, Libs, Software Tools
  - Many stand alone tools will end up being replaced. 
    - Text and data and the purpose of the tools.
    - Explain DNS, DHCP, etc replacement
      - zones, subnets, etc

- Monitoring is the heart of automation.  You cant control what you dont have info on.
   - Instelligence:  Actionable?  Timely?  Relevant?  Correct?  (Cross check it, all must align)

- Behavioral AI.  An expert system, build by experts in Ops and Biz goals.
  - Do not use fuzzy info until you have exhausted discrete/precise info.  And turn the fuzzy info into a discrete/precise data point, so it can be acted on cleanly by logic.
  - N of M failures is not fuzzy, even though it has a scalar value, and not boolean.

- 3 States:  Now, Desired, Current State (Whats Out there?)
  - How to manage.  Importing, synthesizing, checking.
  - Versioning, commits, pre/post-commit logic.
 
- Agent model.  Centralized model.

- Library model.  RPC model.  Framework model.

- ORM vs wrapping lib vs straight SQL/data query.

- Scales,  1000s/millions, not billions.  Can make this "configuration scale" not "production deployment end-user scale".  Optimize only when necessary, use tools that do heavy lifting for Time series data analysis, and import results and last N snippets into OpsDB.

- Selective Data Updating for Pyramid method and Mesh method.

- Compare Pyramid vs Mesh (p2p).  Pros and cons.

- Name spaces.  Different kinds, diff uses, diff formats.  One of the 2 hard problems (+ off by 1)

- Differences between Ops vs Non-Ops code.
  - Making more depencies.  Networked dependencies.  When things are broken, how will your system function?  Will it fail?  Will it make it worse?  Will it make a mess?  Will it corrupt and destroy?


- *** The Progression of an Automation System:  Walk through all the stages **
  - These shouldnt be an order so much, as people can take different routes.   How to evaluate each of these spectrums/axis of data, scalars, would be good.

  1. Manual everything
  2. Kickstarts and auto config  (AWS gets you here)
  3. Sys configuration tools, Monitoring, Centralized Logging, etc.  Normal sys admin process.
  4. Issue tracking systems, change management ticket systems.
    - Good to have different CMS for tickets, because your ops logic will change, but its more useful to track the CMS data right in the ops db for a real record of things, because it lists the complete workloads.
  5. Databases for assets, inventory, etc


- * The more sources of authoritative data, the more data drift and non-alignment between the data (fields tracking similar but non-matching things, naming differences, not able to point to same primary keys, etc)

- Introduce the dotted notation as a universal naming convention, for lookups, it can universally address any type of DAG data:   domain.sub.thing.11.field.subfield.11.arrayfield.20.subsubfield

	- **** Use this DAG lookup to go into YAML, DBs, etc.  Schema Man can allow this.  Can use sub-searches like globs (domain.thing.*.field) and translate that into SQL or whatever for more advanced usage.


- How to Build your own OpsDB.  What you need:
  - View (Webpage, API)
  - DB Backend
    - Method for safely making changes to data
      - Versioning, Change Management
        - Roll backs
        - Pre-Post Commits
        - Locking, to stop problematic race conditions
          - Channeled locking, to limit domains of locks
            - Size of domain, and rate of change and lock duration determine requirements
      - Single choke point for DB changes
        - Web/API all use the same code, so different paths give different results.
        - Role users (scripts) can auto-commit changes, but should go through same process, because needed for auditing, troubleshooting, and maintaining integrity and pre/post-commit logic
  - Pull method, to gather data.  Time Series, Logs, State/Configs, Events, etc
    -  Creates Global Authority DB
      - Can be distributed, if sync. is strong
        - Need Transactions on all pieces of total DB, so that things are changed in block fastion, all this way, then all that way.  Keeping alignment.  (Like a shot in Pool, game.  Stick and balls must line up to make it into the pocket.)
        - Will come later in the process, in the "How to implement" section
      - Selective Replication.  Will have local and global portions.   Easy to separate instances (2 MySQL instances) so taht there is a Global DB (replicated from Master) and a Local DB, pulled from Local, which replicates to Master.
        - In this scenario, the Master will need to have N instances, where N is the number of sub-masters, so it can replicate.  Then it will pull and integrate this data into it's own global system, and then synthesize.
          - This Global pull-integrate-synthesize is then replicated out everywhere, and is the REAL data that can be acted upon.  It has met all constraints and has a view into everything
            - Some Logic can run off of Local data, because it is locally concerned.  When Logic needs to act on Global data, its obvious it needs to be correct and current global data.  Intelligence.
        - Collection is local.  Work from Global.
          - How to work on partitioon?
            - Can use local data for N time, until is stale.  Logic can decide how stale the data can be, can have Rules for lag time allowances.
  - Orchestration.  Remote Execution.  Seall the loop and check.  Post-Provisioning will need to run commands to check that things really worked.  Same as any other type of action. Do the action, get the result, but then go check and make sure it worked.  Check again to see if it failed after some time.  Ensure another action hasnt caused this (acted on the same Resource)
  - Config Management.  Make known changes on a system.  It should be in "X state"
  - State Management.
    - OS Level
    - Service level (dealing with the execution of services, and proper functionoining of the service)
    - Running-Service level (dealing with things inside a running service.  This is a user of the service, instead of a controller, but it is an "administrative" type of use)
  - Work Scheduling
    - Global cron jobs, etc.
      - In maint?  Is right machine (master/slave/role/etc)?  Dont take down prod.
      - Dont ignore failures of jobs.  Keep logs for auditing, so we know what happened, and what it happened for troubleshooting and Root Cause Analysis.
      - Track times for analysis to determine failures of scale-performance changes
  - Capacity Planning.  When will you run out of:  Disk? RAM?  CPU? Connections?  etc
    - Resources of our services.  Network Loadbalancer has N potential connections, and we can determine that by a MAX check on how much its done, and where it has produced failures after MAX_WORKING values have been breached.  Might not be the LB though, just correlation.
  - Access Control.  Authorization to do work.
  - Deployments, as separate from Config
    - Code deploy
    - Data/Schema deploy
      - When tied together.  Ways to avoid problems, ways to increase problems.
      - Lifetimes, rate of change, etc
      - Service up/down.  In/out of LB.  (Active)
  - Network config and planning
    - VLANs.  Hidden systems, ensure not old IPs (collisions)
      - Can defer their use until that HW is proven to not use that IP anymore.  Like its in Escrow.  Once really released, it can be re-used.   Nice.
    - LOM IPs stay with the hardware.  DHCP timeouts, etc.  Server IPs stay with "ServerInstance" (OSInstance)
  - VM Provisioning.  Hybrid.
  - Self Service tools.
  - How to plan to do this in your existing environment.  A map from:  Here -> There.

- States of machines:  Unknown, Unprovisioned/Spare, Provisioned-Inactive, Active, In Maintenance, Transition-To X State, Broken, Fixed (waitig to be Unprovisioned/Spare)

- Planning for projects in the real world
  - The end-date comes first.  Whether you have any say in that is only occassionally true, even if you are asked how long it will take.
  - Things will interrupt your work that were not planned for in the time estimates, and this will mean less work gets done
  - You will have normal duties to attend to, this will interrupt things getting done
  - Meetings.  Whether you enjoy them, are ambivalent, or dislike them, they are going to occur and take time.
  - Mental-Context-switching cost.  Ramp up time.
    - Know what kind of work you are going to start, and pick the best time to do so.  If it needs more ramp-up time, then pick a block where you are less likely to be interrupted.
    - Break your open time periods into "units" of 30 minutes or 2 hours or whatever you can have contiguously, and see what you can FINISH in that time.  It is easy to lose days/weeks to getting little changes made, but not moving ahead in terms of usable progress.
      - When each time block arrives, try to get what you can finish, and hopefully test and put into place, in that 1 session.  This isnt possible for some work, because it's too big, so break that into stages that can fit into one of these time blocks.  A simple method, would be: write it in 1, test it in another, and finally deploy it in the 3rd.


- Go over code reviews, and config reviews.
  - *** Mark this as my personal opinion.  Not as something provable.  This is color. ***
  - Normal pitfalls.  Dont really check, "Yes Stamp".
    - Too style oriented.  Enforcing a style is important in some areas, but less important in others.  It is better to keep a team cohevsive to know these differences, so that on some things you are strict (variable naming) and on other things you are flexible (commenting style).  People write prose more personally than they name variables, and variables have to be used by many people, whereas the message in a comment in based on the author's mental state when they wrote it, which is very subjective, and people have very different styles.
      - I recommend allowing people to have their own unique style in areas that will not harm the ease-of-use and resiliency/robustness of the Logic, and strictness on naming conventions, and basic formatting (indentation)
        - Strictness can be kept inside individual projects, with a general theme to a department or company.  These are degrees to each of this which will make actually working with other people nicer, while 

- ***** Removing classes of work.

- Root Cause Analysis write ups.
  - How to not bullshit these.  Dont lie.  Dont criticize every failure, because failures WILL happen.  The only way to avoid them is to REMOVE the CLASS OF WORK.

- Create a set of Checklists.
  - Automation Spectrum
  - Automation Layers
    - Sub-Components of layers.  How well are they implemented, 1-5 scale or something
  - Talk about how to make your own checklists and scales.  This is flexible, not dogmatic.  The important part is that we can communicate what we are talking about, in a way where multiple individuals and groups can agree, allowing us to work successfully together.

- Maybe?
  - Self-evaluation?  How to evaluate your actions, how to make plans to improve.  
  - Introduce the Basic Laws of Human Stupidity.  Not meant as insult or joke, but as quantitative method of determining the intelligence of an action.  This is the model I will use in this book.
  - Journmanship, apprenticeship.  What we are missing.  Valuing experience.  Im old, of course thats my take.  
  - The benefits of "vanilla" use of tools.  Less upkeep.  Only change what you strictly need to change.  Spend time optimizing only in critical areas.  Reduce things that need to be manually maintained.




